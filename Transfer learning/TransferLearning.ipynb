{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ece3c3c0",
   "metadata": {},
   "source": [
    "# Transfer Learning:\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In our previous session, we explored **Convolutional Neural Networks (CNNs)** as a powerful tool for image classification tasks. Specifically, we trained a CNN to classify different types of leaves. Through that project, we gained experience with:\n",
    "1. Designing CNN architectures from scratch.\n",
    "2. Training a model with multiple convolutional, pooling, and dense layers.\n",
    "3. Evaluating the performance of the CNN on unseen data.\n",
    "\n",
    "While designing and training a CNN from scratch can be effective, it may not always be practical—especially when working with smaller datasets. Training a model from scratch requires a large dataset and significant computational resources.\n",
    "\n",
    "---\n",
    "\n",
    "### Objective of This Session\n",
    "In this session, we will introduce the concept of **transfer learning** and apply it to a new classification task: distinguishing between different types of shoes. We will build on our understanding of CNNs and demonstrate how to leverage pre-trained models to:\n",
    "1. Fine-tune the network for a new task.\n",
    "2. Adapt a pre-trained network's final layers to a specific dataset.\n",
    "3. Optionally, fine-tune earlier layers to improve performance further.\n",
    "\n",
    "---\n",
    "\n",
    "### What is Transfer Learning?\n",
    "**Transfer learning** is a machine learning technique where a model trained on one task is adapted to a related but different task. For example, a model trained on a large dataset like **ImageNet** (which contains millions of images from thousands of categories) can be adapted to classify images from a much smaller dataset, such as our shoe dataset.\n",
    "\n",
    "In this project, we:\n",
    "1. Use a pre-trained CNN model as a feature extractor, modifying its final layers to classify shoe types.\n",
    "2. Fine-tune some earlier layers of the network to adapt them to the new dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### Why Use Transfer Learning?\n",
    "1. **Efficiency**: Leverages the computational power and vast dataset used to train pre-trained models.\n",
    "2. **Accuracy**: Achieves high performance even with a small dataset by reusing learned features.\n",
    "3. **Fewer Resources**: Reduces the need for large datasets and extensive training time.\n",
    "\n",
    "---\n",
    "\n",
    "### Learning Outcomes\n",
    "By completing this session, you will:\n",
    "1. Understand the core principles of transfer learning.\n",
    "2. Learn to adapt pre-trained models to new datasets by modifying layers.\n",
    "3. Gain experience fine-tuning earlier layers of a pre-trained model for optimal results.\n",
    "4. Implement transfer learning in TensorFlow/Keras.\n",
    "\n",
    "---\n",
    "\n",
    "### Dataset\n",
    "The dataset for this session contains images of different types of shoes. The directory structure is organized as follows:\n",
    "```\n",
    "Shoes/\n",
    "├── Train/\n",
    "│   ├── Heels (40 Samples)/\n",
    "│   ├── Oxfords (40 Samples)/\n",
    "├── Test/\n",
    "│   ├── Heels (9 Samples)/\n",
    "│   ├── Oxfords (9 Samples)/\n",
    "```\n",
    "Each folder represents a category of shoes, and the images are appropriately labeled for training and testing.\n",
    "\n",
    "---\n",
    "\n",
    "### Project Workflow\n",
    "1. **Dataset Preparation**:\n",
    "   - Use `ImageDataGenerator` to augment and preprocess the images for training and testing.\n",
    " \n",
    " \n",
    "2. **Adapting a Pre-Trained Model**:\n",
    "   - Load a CNN model trained on ImageNet.\n",
    "   - Replace its final dense layers with new layers for shoe classification.\n",
    "    \n",
    " \n",
    "3. **Training and Fine-Tuning**:\n",
    "   - Train the new layers with the shoe dataset.\n",
    "   - Fine-tune earlier layers to improve performance further.\n",
    "   \n",
    "              \n",
    "4. **Analysis and Discussion**:\n",
    "   - Analyze the model’s performance.\n",
    "   - Discuss the impact of fine-tuning earlier layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76493796",
   "metadata": {},
   "source": [
    "## Loading the Leaf Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f11e334",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,216</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1936</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">61,984</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │         \u001b[38;5;34m1,216\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │         \u001b[38;5;34m6,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1936\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m61,984\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m198\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">69,817</span> (272.73 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m69,817\u001b[0m (272.73 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">69,814</span> (272.71 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m69,814\u001b[0m (272.71 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> (16.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m3\u001b[0m (16.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: conv2d - Conv2D - Trainable: True\n",
      "Layer 1: max_pooling2d - MaxPooling2D - Trainable: True\n",
      "Layer 2: conv2d_1 - Conv2D - Trainable: True\n",
      "Layer 3: max_pooling2d_1 - MaxPooling2D - Trainable: True\n",
      "Layer 4: flatten - Flatten - Trainable: True\n",
      "Layer 5: dense - Dense - Trainable: True\n",
      "Layer 6: dense_1 - Dense - Trainable: True\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model, Sequential, Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the saved Sequential model\n",
    "model = load_model('leaf_classifier_model.h5')\n",
    "\n",
    "# Print the model's architecture\n",
    "model.summary()\n",
    "\n",
    "for i, layer in enumerate(model.layers):\n",
    "    print(f\"Layer {i}: {layer.name} - {layer.__class__.__name__} - Trainable: {layer.trainable}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29845311",
   "metadata": {},
   "source": [
    "**Quick Reminder**\n",
    "\n",
    "In our previous session, we trained a CNN model that achieved a **test accuracy of around 93%**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252f9779",
   "metadata": {},
   "source": [
    "## Loading the New Shoes Dataset and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "401bde9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 64 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n",
      "Found 18 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True,\n",
    "                                   validation_split=0.2) # Specify 10% for validation\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('./Shoes/Train',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 8,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 subset='training')  # Specify that this is the training set\n",
    "\n",
    "validation_set = train_datagen.flow_from_directory('./Shoes/Train',\n",
    "                                                   target_size=(64, 64),\n",
    "                                                   batch_size=8,\n",
    "                                                   class_mode='categorical',\n",
    "                                                   subset='validation')  # Specify that this is the validation set\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory('./Shoes/Test',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 4,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd049a1",
   "metadata": {},
   "source": [
    "## Adapting the Architecture of the Leaf Identifier Model for Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7bf2ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Reconstruct the model layer by layer\n",
    "inputs = Input(shape=(64, 64, 3))\n",
    "x = inputs\n",
    "for layer in model.layers[:-1]:  # Skip the last layer (Dense with 6 units)\n",
    "    x = layer(x)\n",
    "\n",
    "# Add a new layer for transfer learning\n",
    "# Binary classification\n",
    "new_output = Dense(units=2, activation='softmax', name='new_dense_output')(x)\n",
    "\n",
    "# Create a new model\n",
    "new_model = Model(inputs=inputs, outputs=new_output)\n",
    "\n",
    "# Compile the modified model\n",
    "new_model.compile(optimizer='nadam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "test_accuracy = new_model.evaluate(test_set, verbose=0)\n",
    "print(f'Test Accuracy: {test_accuracy[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b24814",
   "metadata": {},
   "source": [
    "**The model has not been trained on the shoe dataset yet.**\n",
    "\n",
    "Let’s evaluate the performance of the leaf identifier model on the shoe dataset **without any additional training**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9697042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Correct: 9 out of 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample</th>\n",
       "      <th>Predicted Label</th>\n",
       "      <th>Actual Label</th>\n",
       "      <th>Correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Oxfords</td>\n",
       "      <td>Oxfords</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Oxfords</td>\n",
       "      <td>Oxfords</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Heels</td>\n",
       "      <td>Heels</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Oxfords</td>\n",
       "      <td>Heels</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Oxfords</td>\n",
       "      <td>Oxfords</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Heels</td>\n",
       "      <td>Oxfords</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Oxfords</td>\n",
       "      <td>Heels</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Oxfords</td>\n",
       "      <td>Heels</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Heels</td>\n",
       "      <td>Heels</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Heels</td>\n",
       "      <td>Oxfords</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Oxfords</td>\n",
       "      <td>Oxfords</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Heels</td>\n",
       "      <td>Oxfords</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Oxfords</td>\n",
       "      <td>Heels</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Oxfords</td>\n",
       "      <td>Heels</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Oxfords</td>\n",
       "      <td>Oxfords</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Heels</td>\n",
       "      <td>Heels</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Heels</td>\n",
       "      <td>Heels</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Heels</td>\n",
       "      <td>Oxfords</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sample Predicted Label Actual Label  Correct\n",
       "0        1         Oxfords      Oxfords     True\n",
       "1        2         Oxfords      Oxfords     True\n",
       "2        3           Heels        Heels     True\n",
       "3        4         Oxfords        Heels    False\n",
       "4        5         Oxfords      Oxfords     True\n",
       "5        6           Heels      Oxfords    False\n",
       "6        7         Oxfords        Heels    False\n",
       "7        8         Oxfords        Heels    False\n",
       "8        9           Heels        Heels     True\n",
       "9       10           Heels      Oxfords    False\n",
       "10      11         Oxfords      Oxfords     True\n",
       "11      12           Heels      Oxfords    False\n",
       "12      13         Oxfords        Heels    False\n",
       "13      14         Oxfords        Heels    False\n",
       "14      15         Oxfords      Oxfords     True\n",
       "15      16           Heels        Heels     True\n",
       "16      17           Heels        Heels     True\n",
       "17      18           Heels      Oxfords    False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get class indices to map predictions to actual class names\n",
    "class_indices = test_set.class_indices\n",
    "class_labels = {v: k for k, v in class_indices.items()}  # Reverse the mapping\n",
    "\n",
    "# Initialize a list to store results\n",
    "results = []\n",
    "\n",
    "# Iterate through the test set\n",
    "correct_count = 0\n",
    "total_samples = 0\n",
    "\n",
    "for i in range(len(test_set)):\n",
    "    # Get a batch of test data\n",
    "    images, labels = test_set[i]\n",
    "    \n",
    "    # Predict the labels\n",
    "    predictions = new_model.predict(images, verbose=0)\n",
    "    \n",
    "    # Convert predictions and actual labels to class indices\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    actual_classes = np.argmax(labels, axis=1)\n",
    "    \n",
    "    # Add results to the list\n",
    "    for j in range(len(images)):\n",
    "        predicted_label = class_labels[predicted_classes[j]]\n",
    "        actual_label = class_labels[actual_classes[j]]\n",
    "        is_correct = predicted_label == actual_label\n",
    "        results.append({\n",
    "            \"Sample\": total_samples + 1,\n",
    "            \"Predicted Label\": predicted_label,\n",
    "            \"Actual Label\": actual_label,\n",
    "            \"Correct\": is_correct\n",
    "        })\n",
    "        if is_correct:\n",
    "            correct_count += 1\n",
    "        total_samples += 1\n",
    "    \n",
    "    # Break loop if last batch is reached (test_set is an infinite generator)\n",
    "    if (i + 1) * test_set.batch_size >= len(test_set.filenames):\n",
    "        break\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Save the table to a CSV file\n",
    "df_results.to_csv(\"prediction_results.csv\", index=False)\n",
    "\n",
    "# Print a summary\n",
    "print(f\"Total Correct: {correct_count} out of {total_samples}\")\n",
    "\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd33c4a",
   "metadata": {},
   "source": [
    "## Training the New Layers (Classification Layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea3147a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9444444179534912\n"
     ]
    }
   ],
   "source": [
    "# Train the modified model on the new dataset\n",
    "history = new_model.fit(training_set, validation_data=validation_set, epochs=10, verbose=0)\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "test_accuracy = new_model.evaluate(test_set, verbose=0)\n",
    "print(f'Test Accuracy: {test_accuracy[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4dda5e",
   "metadata": {},
   "source": [
    "## Fine-Tuning the Early Layers (Feature Extraction Layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a0e1a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy After Fine-Tuning: 0.9444444179534912\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Unfreeze some of the earlier layers\n",
    "for layer in new_model.layers[:4]:  # Example: Unfreeze the first 4 layers\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompile the model with a lower learning rate\n",
    "new_model.compile(optimizer=Adam(learning_rate=1e-5),  # Lower learning rate for fine-tuning\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Continue training the model\n",
    "history_fine_tuning = new_model.fit(training_set, validation_data=validation_set, epochs=10, verbose=0)\n",
    "\n",
    "# Evaluate the model on the test dataset again\n",
    "test_accuracy_fine_tuned = new_model.evaluate(test_set,verbose=0)\n",
    "print(f\"Test Accuracy After Fine-Tuning: {test_accuracy_fine_tuned[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6dd01a",
   "metadata": {},
   "source": [
    "## Why Transfer Learning Works\n",
    "Transfer learning is possible because of how **Neural Networks** learn and organize information hierarchically across their layers. For example, each layer of a CNN extracts increasingly complex features from the input data:\n",
    "\n",
    "1. **Early Layers**:\n",
    "   - Learn to detect **basic patterns** like edges, corners, and textures.\n",
    "   - These patterns are universal and apply to many types of images (e.g., edges in a leaf image are similar to edges in a shoe or a face image).\n",
    "\n",
    "2. **Middle Layers**:\n",
    "   - Combine basic patterns to detect **textures**, **shapes**, and **small objects**.\n",
    "   - For example, these layers might identify curves, rectangles, or patterns specific to a leaf’s structure or the shape of a shoe.\n",
    "\n",
    "3. **Later Layers**:\n",
    "   - Focus on more **task-specific features**, such as combining all learned patterns to classify an entire object.\n",
    "   - For instance, the later layers of a CNN trained on faces might learn to detect noses, eyes, and mouths, ultimately combining these features to recognize the entire face.\n",
    "\n",
    "---\n",
    "\n",
    "### Example: Face Detection\n",
    "- When training a CNN to detect faces:\n",
    "  - **First layers** learn to detect edges and corners, which are universal to any image.\n",
    "  - **Intermediate layers** detect eyes, noses, and mouths (parts of a face).\n",
    "  - **Final layers** combine these features into a high-level representation of the entire face.\n",
    "\n",
    "These early layers—focused on basic feature extraction—are transferable because detecting edges, shapes, or textures in one dataset (e.g., ImageNet) applies equally well to another dataset (e.g., shoes or leaves).\n",
    "\n",
    "---\n",
    "\n",
    "### How Transfer Learning Leverages Pre-Trained Models\n",
    "1. **Feature Extraction**:\n",
    "   - In transfer learning, we reuse the **early layers** of a pre-trained model because they are already excellent at extracting general features like edges and textures.\n",
    "   - These features are **universal** and not tied to any specific dataset.\n",
    "\n",
    "2. **Task-Specific Learning**:\n",
    "   - The **final layers** of a pre-trained model are task-specific. For example:\n",
    "   - To adapt the model, we replace the final layers (classification layers) with new layers tailored to our specific dataset.\n",
    "   - These new later layers are trained from scratch or fine-tuned to learn task-specific features (e.g., distinguishing shoe types).\n",
    "\n",
    "3. **Fine-Tuning**:\n",
    "   - If needed, we can also fine-tune earlier layers, especially if our dataset is significantly different from the original dataset used for pre-training. This allows the model to adapt its feature extraction to better suit the new task.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Insight\n",
    "Transfer learning works because:\n",
    "- **Basic features** (edges, textures, shapes) are transferable across datasets.\n",
    "- **Task-specific features** (e.g., recognizing specific categories) are dataset-dependent and require retraining.\n",
    "- For most applications, simply replacing and fine-tuning the final layers of a pre-trained model is enough to achieve excellent results.\n",
    "\n",
    "This saves time, computational resources, and the need for massive datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
