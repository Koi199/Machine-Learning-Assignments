{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 7 \n",
    "## Objective\n",
    "Build a Long Short-Term Memory (LSTM) recurrent neural network to predict the current global active power at the time step (t), given prior measurements at the time step (t-1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xpAuMVCwfWs8"
   },
   "source": [
    "# Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nxJfRe4bfYVA"
   },
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ir9zwETrfbrp"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZT1f24vHffuf"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nQ47JAxrgmaL"
   },
   "source": [
    "### Importing the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset head:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-12-16 17:24:00</td>\n",
       "      <td>4.216</td>\n",
       "      <td>0.418</td>\n",
       "      <td>234.84</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-12-16 17:25:00</td>\n",
       "      <td>5.360</td>\n",
       "      <td>0.436</td>\n",
       "      <td>233.63</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-12-16 17:26:00</td>\n",
       "      <td>5.374</td>\n",
       "      <td>0.498</td>\n",
       "      <td>233.29</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-12-16 17:27:00</td>\n",
       "      <td>5.388</td>\n",
       "      <td>0.502</td>\n",
       "      <td>233.74</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-12-16 17:28:00</td>\n",
       "      <td>3.666</td>\n",
       "      <td>0.528</td>\n",
       "      <td>235.68</td>\n",
       "      <td>15.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DateTime  Global_active_power  Global_reactive_power  Voltage  \\\n",
       "0 2006-12-16 17:24:00                4.216                  0.418   234.84   \n",
       "1 2006-12-16 17:25:00                5.360                  0.436   233.63   \n",
       "2 2006-12-16 17:26:00                5.374                  0.498   233.29   \n",
       "3 2006-12-16 17:27:00                5.388                  0.502   233.74   \n",
       "4 2006-12-16 17:28:00                3.666                  0.528   235.68   \n",
       "\n",
       "   Global_intensity  Sub_metering_1  Sub_metering_2  Sub_metering_3  \n",
       "0              18.4             0.0             1.0            17.0  \n",
       "1              23.0             0.0             1.0            16.0  \n",
       "2              23.0             0.0             2.0            17.0  \n",
       "3              23.0             0.0             1.0            17.0  \n",
       "4              15.8             0.0             1.0            17.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('household_power_consumption.txt', sep=';', \n",
    "                            parse_dates={'DateTime': ['Date', 'Time']}, \n",
    "                            infer_datetime_format=True, \n",
    "                            low_memory=False,  # Prevent type inference issues\n",
    "                            na_values=['?'])   # Treat '?' as NaN\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"Dataset head:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DateTime                     0\n",
       "Global_active_power      25979\n",
       "Global_reactive_power    25979\n",
       "Voltage                  25979\n",
       "Global_intensity         25979\n",
       "Sub_metering_1           25979\n",
       "Sub_metering_2           25979\n",
       "Sub_metering_3           25979\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing values:\")\n",
    "display(df.isnull().sum())\n",
    "\n",
    "# Fill missing values (e.g., forward-fill)\n",
    "df.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HT8_2UJegtG5"
   },
   "source": [
    "## Create Time Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences function\n",
    "def prepare_sequences(data, seq_length):\n",
    "    \"\"\"Prepare sequences for time series prediction\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:(i + seq_length), 0])\n",
    "        y.append(data[i + seq_length, 0])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "seq_length = 400  # Number of time steps to look back\n",
    "train_split = 0.8  # Training data percentage\n",
    "\n",
    "# Extract and scale the data\n",
    "data = df['Global_active_power'].values.reshape(-1, 1)\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "# Create sequences\n",
    "X, y = prepare_sequences(data_scaled, seq_length)\n",
    "X = np.reshape(X, (X.shape[0], X.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train and Test size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (1659887, 400, 1)\n",
      "Test set shape: (414972, 400, 1)\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test sets\n",
    "train_size = int(len(X) * train_split)\n",
    "X_train = X[:train_size]\n",
    "y_train = y[:train_size]\n",
    "X_test = X[train_size:]\n",
    "y_test = y[train_size:]\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZRRSOJeVjEWV"
   },
   "source": [
    "## Part 2 - Building and Training the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kylea\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "c:\\Users\\kylea\\anaconda3\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling LSTMCell.call().\n\n\u001b[1mDimensions must be equal, but are 400 and 1 for '{{node sequential_7_1/lstm_14_1/lstm_cell_1/MatMul}} = MatMul[T=DT_HALF, grad_a=false, grad_b=false, transpose_a=false, transpose_b=false](sequential_7_1/lstm_14_1/strided_slice_2, sequential_7_1/lstm_14_1/lstm_cell_1/Cast/Cast)' with input shapes: [?,400], [1,128].\u001b[0m\n\nArguments received by LSTMCell.call():\n  • inputs=tf.Tensor(shape=(None, 400), dtype=float16)\n  • states=('tf.Tensor(shape=(None, 32), dtype=float16)', 'tf.Tensor(shape=(None, 32), dtype=float16)')\n  • training=True",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22136\\2316502033.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;31m# Train the model using generators\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m history = regressor.fit(\n\u001b[0m\u001b[0;32m    107\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kylea\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[1;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kylea\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[1;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling LSTMCell.call().\n\n\u001b[1mDimensions must be equal, but are 400 and 1 for '{{node sequential_7_1/lstm_14_1/lstm_cell_1/MatMul}} = MatMul[T=DT_HALF, grad_a=false, grad_b=false, transpose_a=false, transpose_b=false](sequential_7_1/lstm_14_1/strided_slice_2, sequential_7_1/lstm_14_1/lstm_cell_1/Cast/Cast)' with input shapes: [?,400], [1,128].\u001b[0m\n\nArguments received by LSTMCell.call():\n  • inputs=tf.Tensor(shape=(None, 400), dtype=float16)\n  • states=('tf.Tensor(shape=(None, 32), dtype=float16)', 'tf.Tensor(shape=(None, 32), dtype=float16)')\n  • training=True"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Create a data generator to handle large datasets\n",
    "class TimeSeriesGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, data, targets, sequence_length, batch_size=128):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.sequence_length = sequence_length\n",
    "        self.batch_size = batch_size\n",
    "        self.indexes = np.arange(len(data) - sequence_length)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (len(self.indexes) + self.batch_size - 1) // self.batch_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        start_idx = index * self.batch_size\n",
    "        end_idx = min((index + 1) * self.batch_size, len(self.indexes))\n",
    "        batch_indexes = self.indexes[start_idx:end_idx]\n",
    "        \n",
    "        batch_X = np.array([\n",
    "            self.data[idx:idx + self.sequence_length] \n",
    "            for idx in batch_indexes\n",
    "        ])\n",
    "        batch_y = np.array([\n",
    "            self.targets[idx + self.sequence_length - 1] \n",
    "            for idx in batch_indexes\n",
    "        ])\n",
    "        \n",
    "        return batch_X, batch_y\n",
    "\n",
    "# Data preparation\n",
    "sequence_length = 24  # Adjust based on your needs\n",
    "batch_size = 128     # Reduced batch size to manage memory\n",
    "\n",
    "# Create generators for training and validation\n",
    "# Assuming X_train and y_train are your original data arrays\n",
    "train_size = int(0.8 * len(X_train))\n",
    "X_train_data = X_train[:train_size]\n",
    "y_train_data = y_train[:train_size]\n",
    "X_val_data = X_train[train_size:]\n",
    "y_val_data = y_train[train_size:]\n",
    "\n",
    "train_generator = TimeSeriesGenerator(\n",
    "    X_train_data, \n",
    "    y_train_data,\n",
    "    sequence_length,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_generator = TimeSeriesGenerator(\n",
    "    X_val_data,\n",
    "    y_val_data,\n",
    "    sequence_length,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Create the model\n",
    "regressor = Sequential()\n",
    "\n",
    "# First LSTM layer\n",
    "regressor.add(LSTM(units=32,  # Reduced units\n",
    "                  activation='tanh',\n",
    "                  recurrent_activation='sigmoid',\n",
    "                  return_sequences=True,\n",
    "                  input_shape=(sequence_length, 1)))\n",
    "regressor.add(BatchNormalization())\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Second LSTM layer\n",
    "regressor.add(LSTM(units=16,  # Reduced units\n",
    "                  activation='tanh',\n",
    "                  recurrent_activation='sigmoid',\n",
    "                  return_sequences=False))\n",
    "regressor.add(BatchNormalization())\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "regressor.add(Dense(units=1))\n",
    "\n",
    "# Compile with optimized settings\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "regressor.compile(optimizer=optimizer,\n",
    "                 loss='mse',\n",
    "                 metrics=['mae'])\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=0.00001\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train the model using generators\n",
    "history = regressor.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=100,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Function to make predictions (use when needed)\n",
    "def predict_sequence(model, input_sequence):\n",
    "    return model.predict(input_sequence.reshape(1, sequence_length, 1))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "recurrent_neural_network.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
